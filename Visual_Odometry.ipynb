{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "jukit_cell_id": "d3q92lB6Tn"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdalal1/Visual-Odometry/blob/main/Visual_Odometry.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "uDoNjnfFH7"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import datetime\n",
        "import progressbar"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ng4JnJdyCR"
      },
      "source": [
        "file_path = '../dataset/sequences/00/image_0/'\n",
        "left_images = os.listdir(file_path) # list of strings with names of images\n",
        "print(len(left_images))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "HSN51OBlio"
      },
      "source": [
        "plt.figure(figsize=(12,4))\n",
        "plt.imshow(cv2.imread(file_path + left_images[0], 0), cmap='gray')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "qxoYS5ocj6"
      },
      "source": [
        "file_path = '../dataset/sequences/00/'\n",
        "velodyne_files = os.listdir(file_path + 'velodyne/')\n",
        "pointcloud = np.fromfile(file_path + 'velodyne/' + velodyne_files[1], dtype=np.float32)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "0duqSS2wUx"
      },
      "source": [
        "len(pointcloud)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "KV8JDMpY26"
      },
      "source": [
        "pointcloud = pointcloud.reshape((-1, 4)) # 4 columns for x, y, z, intensity"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "VEVDhvOKzI"
      },
      "source": [
        "# %matplotlib notebook"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "2LmqCTNoNL"
      },
      "source": [
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax = fig.add_subplot(111, projection='3d')\n",
        "\n",
        "xs = pointcloud[:, 0][::10]\n",
        "ys = pointcloud[:, 1][::10]\n",
        "zs = pointcloud[:, 2][::10]\n",
        "\n",
        "ax.set_box_aspect([np.ptp(xs), np.ptp(ys), np.ptp(zs)])\n",
        "ax.grid(False)\n",
        "ax.axis('off')\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "ax.view_init(elev=40, azim=180)\n",
        "\n",
        "ax.scatter(xs, ys, zs, s=0.1)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "8rcga3T6Z7"
      },
      "source": [
        "calib = pd.read_csv('../dataset/sequences/00/calib.txt', delimiter=\" \", header=None, index_col=0)\n",
        "print(calib)\n",
        "Tr = np.array(calib.iloc[4]).reshape((3, 4))\n",
        "print(Tr.round(4))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "EtNx4guGkX"
      },
      "source": [
        "class Dataset_Handler():\n",
        "\n",
        "    def __init__(self, sequence, lidar=True, progress_bar=True, low_memory=True):\n",
        "\n",
        "        self.lidar = lidar\n",
        "        self.low_memory = low_memory\n",
        "\n",
        "        self.seq_dir = f\"../dataset/sequences/{sequence}/\"\n",
        "        self.poses_dir = f\"../dataset/poses/{sequence}.txt\"\n",
        "        poses = pd.read_csv(self.poses_dir, delimiter=\" \", header=None)\n",
        "\n",
        "        self.left_image_files = sorted(os.listdir(self.seq_dir + 'image_0'))\n",
        "        self.right_image_files = sorted(os.listdir(self.seq_dir + 'image_1'))\n",
        "        self.velodyne_files = sorted(os.listdir(self.seq_dir + 'velodyne'))\n",
        "        self.num_frames = len(self.left_image_files)\n",
        "        self.lidar_path = self.seq_dir + 'velodyne/'\n",
        "\n",
        "        self.gt = np.zeros((self.num_frames, 3, 4))\n",
        "\n",
        "        for i in range(len(poses)):\n",
        "            self.gt[i] = np.array(poses.iloc[i]).reshape((3, 4))\n",
        "\n",
        "        calib = pd.read_csv(self.seq_dir + 'calib.txt', delimiter=\" \", header=None, index_col=0)\n",
        "        self.P0 = np.array(calib.loc['P0:']).reshape((3, 4))\n",
        "        self.P1 = np.array(calib.loc['P1:']).reshape((3, 4))\n",
        "        self.P2 = np.array(calib.loc['P2:']).reshape((3, 4))\n",
        "        self.P3 = np.array(calib.loc['P3:']).reshape((3, 4))\n",
        "        if self.lidar:\n",
        "            self.Tr = np.array(calib.loc['Tr:']).reshape((3, 4))\n",
        "\n",
        "        if low_memory:\n",
        "            self.reset_frames()\n",
        "            self.first_image_left = cv2.imread(self.seq_dir + 'image_0/' + \n",
        "                                               self.left_image_files[0], 0)\n",
        "            self.first_image_right = cv2.imread(self.seq_dir + 'image_1/' + \n",
        "                                               self.right_image_files[0], 0)\n",
        "            self.second_image_left = cv2.imread(self.seq_dir + 'image_0/' + \n",
        "                                               self.left_image_files[1], 0)\n",
        "            if lidar:\n",
        "                self.first_pointcloud = np.fromfile(self.lidar_path + self.velodyne_files[0],\n",
        "                                                    dtype=np.float32,\n",
        "                                                    count=-1).reshape((-1, 4))\n",
        "            self.imheight = self.first_image_left.shape[0]\n",
        "            self.imwidth = self.first_image_left.shape[1]\n",
        "        else:\n",
        "            self.images_left = []\n",
        "            self.images_right = []\n",
        "            self.pointclouds = []\n",
        "            if progress_bar:\n",
        "                bar = progressbar.ProgressBar(maxval=self.num_frames)\n",
        "                bar.start()\n",
        "            for i, name_left in enumerate(self.left_image_files):\n",
        "                name_right = self.right_image_files[i]\n",
        "                self.images_left.append(cv2.imread(self.seq_dir + 'image_0/' + name_left))\n",
        "                self.images_right.append(cv2.imread(self.seq_dir + 'image_1/' + name_right))\n",
        "                if lidar:\n",
        "                    pointcloud = np.fromfile(self.lidar_path + self.velodyne_files[i],\n",
        "                                             dtype=np.float32, count=-1).reshape((-1, 4))\n",
        "                    self.pointclouds.append(pointcloud)\n",
        "                if progress_bar:\n",
        "                    bar.update(i+1)\n",
        "                self.imheight = self.images_left[0].shape[0]\n",
        "                self.imwidth = self.images_right[0].shape[1]\n",
        "\n",
        "    def reset_frames(self):\n",
        "        self.images_left = (cv2.imread(self.seq_dir + 'image_0/' + name_left, 0)\n",
        "                            for name_left in self.left_image_files)\n",
        "        self.images_right= (cv2.imread(self.seq_dir + 'image_1/' + name_right, 0)\n",
        "                            for name_right in self.right_image_files)\n",
        "        if self.lidar:\n",
        "            self.pointclouds = (np.fromfile(self.lidar_path + velodyne_file,\n",
        "                                           dtype=np.float32,\n",
        "                                           count=-1).reshape((-1, 4))\n",
        "                               for velodyne_file in self.velodyne_files)\n",
        "        pass\n",
        "        "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "NfHA0ilM1n"
      },
      "source": [
        "handler = Dataset_Handler(\"00\", lidar=True, low_memory=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ZNysSNcwx0"
      },
      "source": [
        "plt.imshow(handler.first_image_left, cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(handler.first_image_right, cmap='gray')\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "BWNLHYCYz4"
      },
      "source": [
        "def compute_left_disparity_map(img_left, img_right, matcher='bm', rgb=False, verbose=True):\n",
        "    # the rgb argument can be taken out, we will not be using it.\n",
        "    sad_window = 6\n",
        "    num_disparities = sad_window*16\n",
        "    block_size = 11\n",
        "    matcher_name = matcher\n",
        "    \n",
        "    if matcher_name == 'bm':\n",
        "        matcher = cv2.StereoBM_create(numDisparities=num_disparities,\n",
        "                                      blockSize=block_size\n",
        "                                     )\n",
        "        \n",
        "    elif matcher_name == 'sgbm':\n",
        "        matcher = cv2.StereoSGBM_create(numDisparities=num_disparities,\n",
        "                                        minDisparity=0,\n",
        "                                        blockSize=block_size,\n",
        "                                        P1 = 8 * 1 * block_size ** 2,\n",
        "                                        P2 = 32 * 1 * block_size ** 2,\n",
        "                                        mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY\n",
        "                                       )\n",
        "    if rgb:\n",
        "        img_left = cv2.cvtColor(img_left, cv2.COLOR_BGR2GRAY)\n",
        "        img_right = cv2.cvtColor(img_right, cv2.COLOR_BGR2GRAY)\n",
        "    start = datetime.datetime.now()\n",
        "    disp_left = matcher.compute(img_left, img_right).astype(np.float32)/16\n",
        "    end = datetime.datetime.now()\n",
        "    if verbose:\n",
        "        print(f'Time to compute disparity map using Stereo{matcher_name.upper()}:', end-start)\n",
        "    \n",
        "    return disp_left\n",
        "    "
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "2SEkDTJARh"
      },
      "source": [
        "disp = compute_left_disparity_map(handler.first_image_left,\n",
        "                                  handler.first_image_right,\n",
        "                                  matcher='sgbm',\n",
        "                                  verbose=False)\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.imshow(disp);\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "6RIdW7oPPI"
      },
      "source": [
        "k, r, t, _, _, _, _ = cv2.decomposeProjectionMatrix(handler.P1)\n",
        "print(k)\n",
        "print(r)\n",
        "print((t / t[3]).round())"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "0UNIvBjzUc"
      },
      "source": [
        "def decompose_projection_matrix(P):\n",
        "    k, r, t, _, _, _, _ = cv2.decomposeProjectionMatrix(P)\n",
        "    t = (t / t[3])[:3]\n",
        "    return k, r, t"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "0Wzfdk9RP4"
      },
      "source": [
        "def calc_depth_map(disp_left, k_left, t_left, t_right, rectified=True):\n",
        "    # he explains what's going on with the rectified term and what it means\n",
        "    # in video 3 ~48:00, it's not what you think\n",
        "    if rectified:\n",
        "        b = t_right[0] - t_left[0]\n",
        "    else:\n",
        "        b = t_left[0] - t_right[0]\n",
        "\n",
        "    f = k_left[0, 0]\n",
        "    \n",
        "    disp_left[disp_left == 0] = 0.1\n",
        "    disp_left[disp_left == -1] = 0.1\n",
        "\n",
        "    depth_map = np.ones(disp_left.shape)\n",
        "    depth_map = f * b / disp_left\n",
        "\n",
        "    return depth_map"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "SG65qIc8Lz"
      },
      "source": [
        "k_left, r_left, t_left = decompose_projection_matrix(handler.P0)\n",
        "k_right, r_right, t_right = decompose_projection_matrix(handler.P1)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ZZwwU3CvEe"
      },
      "source": [
        "depth = calc_depth_map(disp, k_left, t_left, t_right)\n",
        "plt.figure(figsize=(12, 4))\n",
        "depth[depth == depth.max()] = 650\n",
        "plt.imshow(depth)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "C67Ltv8fbo"
      },
      "source": [
        "plt.hist(depth.flatten())\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "3aaLn4E9ib"
      },
      "source": [
        "mask = np.zeros(depth.shape, dtype=np.uint8)\n",
        "ymax = depth.shape[0]\n",
        "xmax = depth.shape[1]\n",
        "cv2.rectangle(mask, (96, 0), (xmax, ymax), (255), thickness=-1)\n",
        "plt.imshow(mask);\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "FOEis0JSoY"
      },
      "source": [
        "def stereo_2_depth(img_left, img_right, P0, P1, matchers='bm', rgb=False, verbose=True,\n",
        "                   rectified=True):\n",
        "    # Compute disparity map\n",
        "    disp = compute_left_disparity_map(img_left,\n",
        "                                      img_right,\n",
        "                                      matcher=matchers,\n",
        "                                      rgb=rgb,\n",
        "                                      verbose=verbose)\n",
        "    # decompose projection matrix\n",
        "    k_left, r_left, t_left = decompose_projection_matrix(P0)\n",
        "    k_right, r_right, t_right = decompose_projection_matrix(P1)\n",
        "\n",
        "    # calculate depth map for left camera\n",
        "    depth = calc_depth_map(disp, k_left, t_left, t_right, rectified=rectified)\n",
        "\n",
        "    return depth"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "C8RPMBZETp"
      },
      "source": [
        "stereo_depth = stereo_2_depth(handler.first_image_left,\n",
        "                       handler.first_image_right,\n",
        "                       handler.P0,\n",
        "                       handler.P1,\n",
        "                       matchers='sgbm',\n",
        "                       verbose=True)\n",
        "plt.imshow(stereo_depth)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Q7FGtHl5VM"
      },
      "source": [
        "pcloud = handler.first_pointcloud\n",
        "print(pcloud.shape)\n",
        "trimmed_pcloud = pcloud[pcloud[:, 0] > 0]\n",
        "print(trimmed_pcloud.shape)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "bl8UjdgfW0"
      },
      "source": [
        "hom_pcloud = np.hstack([trimmed_pcloud[:, :3], np.ones(trimmed_pcloud.shape[0]).reshape((-1, 1))])\n",
        "cam_xyz = handler.Tr.dot(trimmed_pcloud.T)\n",
        "cam_xyz /= cam_xyz[2]\n",
        "cam_xyz = np.vstack([cam_xyz, np.ones(cam_xyz.shape[1])])\n",
        "projection = handler.P0.dot(cam_xyz)\n",
        "projection[:,:5].T"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "IQRnaCECCn"
      },
      "source": [
        "pixel_coords = np.round(projection.T, 0).astype('int')\n",
        "pixel_coords[:5]"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "bvZIUCB4AA"
      },
      "source": [
        "def pointcloud2image(pointcloud, imheight, imwidth, Tr, P0):\n",
        "    \n",
        "    pointcloud = pointcloud[pointcloud[:, 0] > 0]\n",
        "    reflectance = pointcloud[:, 3]\n",
        "    # make pointcloud homogenous (X, Y, Z, 1)\n",
        "    pointcloud = np.hstack([pointcloud[:, :3], np.ones(pointcloud.shape[0]).reshape((-1, 1))])\n",
        "\n",
        "    # Transform points into 3D coordinate frame of camera\n",
        "    cam_xyz = Tr @ pointcloud.T\n",
        "\n",
        "    # clip off points with negative z values\n",
        "    cam_xyz = cam_xyz[:, cam_xyz[2] > 0]\n",
        "\n",
        "    depth = cam_xyz[2].copy()\n",
        "\n",
        "    cam_xyz /= cam_xyz[2]\n",
        "    cam_xyz = np.vstack([cam_xyz, np.ones(cam_xyz.shape[1])])\n",
        "    projection = P0 @ cam_xyz\n",
        "    pixel_coordinates = np.round(projection.T,0)[:,:2].astype(int)\n",
        "\n",
        "    # filter out points that are outside of the image\n",
        "    indices = np.where((pixel_coordinates[:, 0] < imwidth)\n",
        "                       & (pixel_coordinates[:, 0] >= 0)\n",
        "                       & (pixel_coordinates[:, 1] < imheight)\n",
        "                       & (pixel_coordinates[:, 1] >= 0))\n",
        "\n",
        "    pixel_coordinates = pixel_coordinates[indices]\n",
        "    depth = depth[indices]\n",
        "    reflectance = reflectance[indices]\n",
        "\n",
        "    render = np.zeros((imheight, imwidth))\n",
        "    for j, (u,v) in enumerate(pixel_coordinates):\n",
        "        # if u >= imwidth or u < 0:\n",
        "        #     continue\n",
        "        # if v >= imheight or v < 0:\n",
        "        #     continue\n",
        "        render[v,u] = depth[j]\n",
        "\n",
        "    # render[render == 0.0] = 3861.45\n",
        "\n",
        "    return render"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "MBVVUsEvYC"
      },
      "source": [
        "render = pointcloud2image(handler.first_pointcloud, handler.imheight, handler.imwidth, handler.Tr, handler.P0)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "KGHCfn9w3t"
      },
      "source": [
        "plt.figure(figsize=(13,5))\n",
        "plt.imshow(render)\n",
        "plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "gEqMtEd5EH"
      },
      "source": [
        "for i, d in enumerate(stereo_depth[200:, :].flatten()):\n",
        "    if render[200:,:].flatten()[i] == 0:\n",
        "        continue\n",
        "    print(\"stereo depth: \", d, \"lidar depth: \", render[200:,:].flatten()[i])\n",
        "    if i > 1000:\n",
        "        break"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "T6rYhdsOJv"
      },
      "source": [
        "handler.reset_frames()\n",
        "\n",
        "pcloud_frames = (pointcloud2image(next(handler.pointclouds),\n",
        "                                  handler.imheight,\n",
        "                                  handler.imwidth,\n",
        "                                  handler.Tr,\n",
        "                                  handler.P0)\n",
        "                for _ in range(handler.num_frames))\n",
        "\n",
        "# poses = (gt for gt in handler.gt)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "fWPvquVBwq"
      },
      "source": [
        "handler.reset_frames()\n",
        "poses = (gt for gt in handler.gt)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "znSRyTfOyc"
      },
      "source": [
        "# display the images and the pointclouds in cool ways for fun\n",
        "\n",
        "xs = []\n",
        "ys = []\n",
        "zs = []\n",
        "\n",
        "compute_times = []\n",
        "fig = plt.figure(figsize=(4, 4))\n",
        "ax = fig.add_subplot(projection='3d')\n",
        "ax.view_init(elev=-20, azim=270)\n",
        "ax.plot(handler.gt[:, 0, 3], handler.gt[:, 1, 3], handler.gt[:, 2, 3], c='k')\n",
        "ax.set_xlabel('X')\n",
        "ax.set_ylabel('Y')\n",
        "ax.set_zlabel('Z')\n",
        "\n",
        "\n",
        "stereo_l = handler.images_left\n",
        "stereo_r = handler.images_right\n",
        "\n",
        "for i in range(handler.num_frames // 50):\n",
        "    img_l = next(stereo_l)\n",
        "    img_r = next(stereo_r)\n",
        "    start = datetime.datetime.now()\n",
        "    disp = compute_left_disparity_map(img_l, img_r, matcher='sgbm')\n",
        "    disp /= disp.max()\n",
        "    # disp = 1 - disp\n",
        "    disp = (disp*255).astype('uint8')\n",
        "    disp = cv2.applyColorMap(disp, cv2.COLORMAP_RAINBOW)\n",
        "    pcloud = next(pcloud_frames)\n",
        "    pcloud /= pcloud.max()\n",
        "    pcloud = (pcloud*255).astype('uint8')\n",
        "\n",
        "    gt = next(poses)\n",
        "    xs.append(gt[0, 3])\n",
        "    ys.append(gt[1, 3])\n",
        "    zs.append(gt[2, 3])\n",
        "    plt.plot(xs, ys, zs, c='chartreuse')\n",
        "    plt.pause(0.000000000000000001)\n",
        "    cv2.imshow('camera', img_l)\n",
        "    cv2.imshow('disparity', disp)\n",
        "    cv2.imshow('lidar', pcloud)\n",
        "    cv2.waitKey(1)\n",
        "\n",
        "    end = datetime.datetime.now()\n",
        "    compute_times.append(end-start)\n",
        "\n",
        "plt.close()\n",
        "cv2.destroyAllWindows()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "eAwbfvQkti"
      },
      "source": [
        "def extract_features(image, detector='sift', mask=None):\n",
        "    if detector == 'sift':\n",
        "        det = cv2.SIFT_create()\n",
        "    elif detector == 'orb':\n",
        "        det = cv2.ORB_create()\n",
        "    \n",
        "    kp, des = det.detectAndCompute(image, mask) # key points, descriptors\n",
        "\n",
        "    return kp, des"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "ISKPvrJfwW"
      },
      "source": [
        "def match_features(des1, des2, matching='BF', detector='sift', sort=False, k=2):\n",
        "\n",
        "    if matching == 'BF':\n",
        "        if detector == 'sift':\n",
        "            matcher = cv2.BFMatcher_create(cv2.NORM_L2, crossCheck=False)\n",
        "        elif detector == 'orb':\n",
        "            matcher = cv2.BFMatcher_create(cv2.NORM_HAMMING2, crossCheck=False)\n",
        "    elif matching == 'FLANN':\n",
        "        FLANN_INDEX_KDTREE = 1\n",
        "        index_params = dict(algorithm=FLANN_INDEX_KDTREE)\n",
        "        search_params = dict(checks=50)\n",
        "        matcher = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    matches = matcher.knnMatch(des1, des2, k=k)\n",
        "\n",
        "    if sort:\n",
        "        matches = sorted(matches, key=lambda x: x[0].distance)\n",
        "\n",
        "    return matches"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "BrWCUCw1k6"
      },
      "source": [
        "def visualize_matches(image1, kp1, image2, kp2, match):\n",
        "    image_matches = cv2.drawMatches(image1, kp1, image2, kp2, match, None, flags=2)\n",
        "    plt.figure(figsize=(16,6), dpi=100)\n",
        "    plt.imshow(image_matches)\n",
        "    plt.show()"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "lthTiL5IRY"
      },
      "source": [
        "def filter_matches_distance(matches, dist_threshold):\n",
        "    filtered_matches = []\n",
        "    # m, n are the two nearest neighbors for each match\n",
        "    for m, n in matches:\n",
        "        if m.distance <= dist_threshold * n.distance:\n",
        "            filtered_matches.append(m)\n",
        "\n",
        "    return filtered_matches"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "RpfdKBzupf"
      },
      "source": [
        "# using sift\n",
        "\n",
        "image_left = handler.first_image_left\n",
        "image_right = handler.first_image_right\n",
        "image_plus1 = handler.second_image_left\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "kp0, des0 = extract_features(image_left, 'sift', mask)\n",
        "kp1, des1 = extract_features(image_plus1, 'sift', mask)\n",
        "matches = match_features(des0, des1, matching='BF', detector='sift', sort=False, k=2)\n",
        "print('number of matches before filtering:', len(matches))\n",
        "matches = filter_matches_distance(matches, 0.3)\n",
        "print('number of matches after filtering:', len(matches))\n",
        "end = datetime.datetime.now()\n",
        "print('time to compute matches:', end-start)\n",
        "visualize_matches(image_left, kp0, image_right, kp1, matches)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "WznavzJq07"
      },
      "source": [
        "# using orb\n",
        "\n",
        "image_left = handler.first_image_left\n",
        "image_right = handler.first_image_right\n",
        "image_plus1 = handler.second_image_left\n",
        "\n",
        "start = datetime.datetime.now()\n",
        "kp0, des0 = extract_features(image_left, 'orb', mask)\n",
        "kp1, des1 = extract_features(image_plus1, 'orb', mask)\n",
        "matches = match_features(des0, des1, matching='BF', detector='orb', sort=False, k=2)\n",
        "print('number of matches before filtering:', len(matches))\n",
        "matches = filter_matches_distance(matches, 0.3)\n",
        "print('number of matches after filtering:', len(matches))\n",
        "end = datetime.datetime.now()\n",
        "print('time to compute matches:', end-start)\n",
        "visualize_matches(image_left, kp0, image_right, kp1, matches)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "DBxzn0MnZp"
      },
      "source": [
        "def estimate_motion(matches, kp1, kp2, k, depth1, max_depth=3000):\n",
        "    \n",
        "    rmat = np.eye(3)\n",
        "    tvec = np.zeros((3, 1))\n",
        "\n",
        "    image1_points = np.float32([kp1[m.queryIdx].pt for m in matches])\n",
        "    image2_points = np.float32([kp2[m.trainIdx].pt for m in matches])\n",
        "\n",
        "    cx = k[0, 2]\n",
        "    cy = k[1, 2]\n",
        "    fx = k[0, 0]\n",
        "    fy = k[1, 1]\n",
        "\n",
        "    object_points = np.zeros((0, 3))\n",
        "    delete = []\n",
        "\n",
        "    for i, (u, v) in enumerate(image1_points):\n",
        "        z = depth1[int(round(v)), int(round(u))]\n",
        "\n",
        "        if z > max_depth:\n",
        "            delete.append(i)\n",
        "            continue\n",
        "        \n",
        "        # we need to subtract cx and cy to move the origin back into the center\n",
        "        # of the image\n",
        "\n",
        "        # we're trying to go back to xy coordinates in meters now\n",
        "\n",
        "        # pretty sure this equation is in his notes?\n",
        "        x = z * (u - cx) / fx\n",
        "        y = z * (v - cy) / fy\n",
        "\n",
        "        # neural network with monocular depth estimation? that sounds like a\n",
        "        # portfolio post to me right there. He mentions this in video 5\n",
        "        # around 26:50\n",
        "        \n",
        "        object_points = np.vstack([object_points, np.array([x, y, z])])\n",
        "\n",
        "        # this is the same thing, but slower\n",
        "        # object_points = np.vstack([object_points, np.linalg.inv(k).dot(z*np.array([u, v, 1])]))\n",
        "        # np.inv is more computationally demanding than doing the algebra by hand \n",
        "\n",
        "    image1_points = np.delete(image1_points, delete, 0)\n",
        "    image2_points = np.delete(image2_points, delete, 0)\n",
        "\n",
        "    _, rvec, tvec, inliers = cv2.solvePnPRansac(object_points, image2_points, k, None)\n",
        "    rmat = cv2.Rodrigues(rvec)[0]\n",
        "\n",
        "    return rmat, tvec, image1_points, image2_points"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "BlFtSotRhr"
      },
      "source": [
        "k, r, t, _, _, _, _ = cv2.decomposeProjectionMatrix(handler.P0)\n",
        "k"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "6jkGWfHEhu"
      },
      "source": [
        "handler.reset_frames()\n",
        "poses = (gt for gt in handler.gt)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Ics9EomnEA"
      },
      "source": [
        "# np.printoptions(precision=4, suppress=True)\n",
        "rmat, tvec, image1_points, image2_points = estimate_motion(matches, kp0, kp1, k, depth)\n",
        "print('rotation matrix:')\n",
        "print(rmat.round(4))\n",
        "print('translation vector')\n",
        "print(tvec.round(4))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "hpITTjXMnK"
      },
      "source": [
        "np.printoptions(precision=3, suppress=True)\n",
        "transformation_matrix = np.hstack([rmat, tvec])\n",
        "print(transformation_matrix.round(3))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "HlfswSHwjX"
      },
      "source": [
        "hom_trans_mat = np.eye(4)\n",
        "hom_trans_mat"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "MZi8OoKKjq"
      },
      "source": [
        "hom_trans_mat[:3, :3] = rmat\n",
        "hom_trans_mat[:3, 3] = tvec.T\n",
        "hom_trans_mat.round(4)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "IKVoFrnych"
      },
      "source": [
        "np.linalg.inv(hom_trans_mat)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "YEogaHaK2V"
      },
      "source": [
        "print(handler.gt[1].round(4))"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "h8dAyg6dM2"
      },
      "source": [
        "handler.reset_frames()\n",
        "poses = (gt for gt in handler.gt)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "Ja50dZjAXJ"
      },
      "source": [
        "def visual_odometry(handler, detector='sift', matching='BF', filter_match_distance=None,\n",
        "                    stereo_matcher='sgbm', mask=None, subset=None, plot=False):\n",
        "    # determine if handler has lidar data\n",
        "    lidar = handler.lidar\n",
        "\n",
        "    # report methods being used to user\n",
        "    print('generating disparities with stereo{}'.format(str.upper(stereo_matcher)))\n",
        "    print('detecting features with {} and matching with {}'.format(str.upper(detector),\n",
        "                                                                   matching))\n",
        "    if filter_match_distance is not None:\n",
        "        print('filtering matches with distance ratio of {}*distance'.format(filter_match_distance))\n",
        "    if lidar:\n",
        "        print('improving stereo depth estimation with lidar data')\n",
        "    if subset is not None:\n",
        "        num_frames = subset\n",
        "    else:\n",
        "        num_frames = handler.num_frames\n",
        "\n",
        "    if plot:\n",
        "        fig = plt.figure(figsize=(14, 14))\n",
        "        ax = fig.add_subplot(projection='3d')\n",
        "        ax.view_init(elev=-20, azim=270)\n",
        "        xs = handler.gt[:, 0, 3]\n",
        "        ys = handler.gt[:, 1, 3]\n",
        "        zs = handler.gt[:, 2, 3]\n",
        "        ax.set_box_aspect((np.ptp(xs), np.ptp(ys), np.ptp(zs)))\n",
        "        ax.plot(xs, ys, zs, c='k')\n",
        "\n",
        "    # establish a homogenous transformation matrix, first pose is identity\n",
        "    T_tot = np.eye(4)\n",
        "    trajectory = np.zeros((num_frames, 3, 4))\n",
        "    trajectory[0] = T_tot[:3, :]\n",
        "    imheight = handler.imheight\n",
        "    imwidth = handler.imwidth\n",
        "\n",
        "    # decompose left camera porjection matrix to get instrinsic k matrix\n",
        "    k_left, r_left, t_left = decompose_projection_matrix(handler.P0)\n",
        "\n",
        "    if handler.low_memory:\n",
        "        handler.reset_frames()\n",
        "        image_plus1 = next(handler.images_left)\n",
        "\n",
        "    # iterate through all frames of the sequence\n",
        "    for i in range(num_frames - 1):\n",
        "        start = datetime.datetime.now()\n",
        "\n",
        "        if handler.low_memory:\n",
        "            image_left = image_plus1\n",
        "            image_plus1 = next(handler.images_left)\n",
        "            image_right = next(handler.images_right)\n",
        "        else:\n",
        "            image_left = handler.images_left[i]\n",
        "            image_plus1 = handler.images_left[i+1]\n",
        "            image_right = handler.images_right[i]\n",
        "\n",
        "        depth = stereo_2_depth(image_left,\n",
        "                               image_right,\n",
        "                               P0=handler.P0,\n",
        "                               P1=handler.P1,\n",
        "                               matchers=stereo_matcher,\n",
        "                               verbose=False)\n",
        "        \n",
        "        if lidar:\n",
        "            if handler.low_memory:\n",
        "                pointcloud = next(handler.pointclouds)\n",
        "            else:\n",
        "                pointcloud = handler.pointclouds[i]\n",
        "\n",
        "            lidar_depth = pointcloud2image(pointcloud,\n",
        "                                           imheight=imheight,\n",
        "                                           imwidth=imwidth,\n",
        "                                           Tr=handler.Tr,\n",
        "                                           P0=handler.P0)\n",
        "\n",
        "            indices = np.where(lidar_depth > 0)\n",
        "            depth[indices] = lidar_depth[indices] # this is stereo depth, we substitute it with lidar depth\n",
        "\n",
        "        # get keypoints and descriptors for left camera image of two sequential frames\n",
        "        kp0, des0 = extract_features(image_left, detector, mask)\n",
        "        kp1, des1 = extract_features(image_plus1, detector, mask)\n",
        "\n",
        "        # get matches between features detected in two subsequent frames\n",
        "        matches_unfilt = match_features(des0,\n",
        "                                        des1,\n",
        "                                        matching=matching,\n",
        "                                        detector=detector)\n",
        "        # print(f'number of matches before filtering: {len(matches_unfilt)}')\n",
        "\n",
        "        # filter matches if a distance threshold is provided by user\n",
        "        if filter_match_distance is not None:\n",
        "            matches = filter_matches_distance(matches_unfilt, filter_match_distance)\n",
        "        else:\n",
        "            matches = matches_unfilt\n",
        "\n",
        "        # print(f'number of matches after filtering: {len(matches)}')\n",
        "        # print('length of kp0: {}, length of kp1: {}'.format(len(kp0), len(kp1)))\n",
        "\n",
        "        # estimate motion between sequential images of the left camera\n",
        "        # print(f\"kp0: \\n{kp0}\")\n",
        "        # print(f\"kp1: \\n{kp1}\")\n",
        "        # print(f\"k_left: \\n{k_left}\")\n",
        "\n",
        "        rmat, tvec, img1_points, img2_points = estimate_motion(matches,\n",
        "                                                              kp0,\n",
        "                                                              kp1,\n",
        "                                                              k_left,\n",
        "                                                              depth)\n",
        "\n",
        "        # create a blank homogenous transformation matrix\n",
        "        # print(f\"rmat: {rmat.round(4)}\")\n",
        "        # print(f\"tvec: {tvec.round(4)}\")\n",
        "        Tmat = np.eye(4)\n",
        "        Tmat[:3, :3] = rmat\n",
        "        Tmat[:3, 3] = tvec.T\n",
        "\n",
        "        # print(f\"Tmat: {Tmat.round(4)}\")\n",
        "        # print(f\"T_tot: {T_tot.round(4)}\")\n",
        "        T_tot = T_tot @ np.linalg.inv(Tmat)\n",
        "        # print(f\"T_tot: {T_tot.round(4)}\")\n",
        "\n",
        "        trajectory[i+1, :, :] = T_tot[:3, :]\n",
        "\n",
        "        end = datetime.datetime.now()\n",
        "        print('time to compute frame {}:'.format(i+1), end-start)\n",
        "\n",
        "        if plot:\n",
        "            xs = trajectory[:i+2, 0, 3]\n",
        "            ys = trajectory[:i+2, 1, 3]\n",
        "            zs = trajectory[:i+2, 2, 3]\n",
        "            plt.plot(xs, ys, zs, c='chartreuse')\n",
        "            # plt.show()\n",
        "            plt.pause(1e-32)\n",
        "\n",
        "    # if plot:\n",
        "        # plt.close()\n",
        "\n",
        "    return trajectory"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "TaOd2NJY71"
      },
      "source": [
        "trajectory_test = visual_odometry(handler,\n",
        "                                  detector='sift',\n",
        "                                  matching='BF',\n",
        "                                  filter_match_distance=0.7,\n",
        "                                  stereo_matcher='sgbm',\n",
        "                                  mask=mask,\n",
        "                                  # subset=50,\n",
        "                                  plot=True)"
      ],
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "metadata": {
        "jukit_cell_id": "kcPG5BkOru"
      },
      "source": [],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "python",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}